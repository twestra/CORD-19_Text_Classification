Background: The cessation of lock-down measures will require an effective testing strategy. Much focus at the beginning of the UK's Covid-19 epidemic was directed to deficiencies in the national testing capacity. The quantity of tests may seem an important focus, but other characteristics are likely more germane. False positive tests are more probable than positive tests when the overall population has a low prevalence of the disease, even with highly accurate tests.
Methods: We modify an SIR model to include quarantines states and test performance using publicly accessible estimates for the current situation. Three scenarios for cessation of lock-down measures are explored: (1) immediate end of lock-down measures, (2) continued lock-down with antibody testing based immunity passports, and (3) incremental relaxation of lock-down measures with active viral testing. Sensitivity, specificity, prevalence and test capacity are modified for both active viral and antibody testing to determine their population level effect on the continuing epidemic.
Findings: Diagnostic uncertainty can have a large effect on the epidemic dynamics of Covid-19 within the UK. The dynamics of the epidemic are more sensitive to test performance and targeting than test capacity. The quantity of tests is not a substitute for an effective strategy. Poorly targeted testing has the propensity to exacerbate the peak in infections.
Interpretation: The assessment that 'no test is better than a bad test' is broadly supported by the present analysis. Antibody testing is unlikely to be a solution to the lock-down, regardless of test quality or capacity. A well designed active viral testing strategy combined with incremental relaxation of the lock-down measures is shown to be a potential strategy to restore some social activity whilst continuing to keep infections low.
The UK government's Covid-19 epidemic management strategy has been influenced by epidemiological modelling conducted by a number of research groups [1, 2] . The analysis of the relative impact of different mitigation and suppression strategies has influenced the current approach. The "only viable strategy at the current time" is to suppress the epidemic with all available measures, including school closures and social distancing of the entire population [3] . These analyses have highlighted from the beginning that the eventual relaxation of lock-down measures would be problematic [3, 4] . Without a considered cessation of the suppression strategies the risk of a second wave becomes signficant, possibly of greater magnitude than the first as the SARS-CoV-2 virus is now endemic in the population [5, 6] .
Although much attention has been focused on the number of tests being conducted [7, 8] , not enough attention has been given to the issues of imperfect testing. Whilst poorly performing tests have not been prominent in public discourse, evidence suggests they are epidemiologically significant. The failure to detect the virus in infected patients can be a significant problem in high-throughput settings operating under severe pressure [9] . Evidence suggest that this is indeed the case [10, 11, 12, 13] .
Everyone seems to agree that testing will be a pillar of whatever approach is employed to relax the current social distancing measures [14] . The public are rapidly becoming aware of the difference between the 'have you got it?' tests for detecting active cases, and the 'have you had it?' tests for the presence of antibodies, which imply some immunity to . What may be less obvious is that these different tests need to maximise different test characteristics.
To be useful in ending the current social distancing measures, active viral tests need to maximise the sensitivity. How good the test is at telling you that you have the disease. High sensitivity reduces the chance of missing people who have the virus who may go on to infect others. There is an additional risk that an infected person who has been incorrectly told they do not have the disease, when in fact they do, may behave in a more reckless manner than if their disease status were uncertain.
The second testing approach, seeking to detect the presence of antibodies to identify those who have had the disease would be used in a different strategy. This strategy would involve detecting those who have successfully overcome the virus, and are likely to have some level of immunity (or at least reduced susceptibility to more serious illness if they are infected again), so are relatively safe to relax their personal social distancing measures. This strategy would require a high test specificity, aiming to minimise how often the test tells someone they have had the disease when they haven't. A false positive tells people they have immunity when they don't, which is even worse than when people are uncertain about their viral history.
2 Introduction to test statistics: What makes a 'good' test?
In order to answer this question there are a number of important statistics:
Sensitivity σ -Out of those who actually have the disease, that fraction that received a positive test result.
Specificity τ -Out of these who did not have the disease, the fraction that received a negative test result.
The statistics that characterise the performance of the test are computed from a confusion matrix (Table 1) . We test n inf ected people who have Covid-19, and n healthy people who do not have Covid-19. In the first group, a people correctly test positive and c falsely test negative. Among healthy people, b will falsely test positive, and d will correctly test negative. From this confusion matrix the sensitivity is given by (1) and the specificity by (2) .
2 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 22, 2020. .
Sensitivity is the ratio of correct positive tests to the total number of infected people involved in the study characterising the test. The specificity is the ratio of the correct negative tests to the total number of healthy people. Importantly, these statistics depend only on the test itself and do not depend on the population the test is intended to be used upon.
Computing the statistics require a definitive way to determine the true viral status of a patient; a so-called gold standard. If there is doubt about in which column a patient falls, the confusion matrix cannot be constructed. When novel tests are employed the confusion matrix can be very challenging to rigorously assess in the midst of a fast moving epidemic [15, 16, 17] .
When the test is used for diagnostic purposes, the characteristics of the population being tested become important for interpreting the test results. To interpret the diagnostic value of a positive or negative test result the following statistics must be used:
Prevalence p -The proportion of people in the target population that have the disease tested for.
Positive Predictive Value P P V -How likely one is to have the disease given a positive test result.
Negative Predictive Value N P V -How likely one is to not have the disease, given a negative test result.
The P P V and N P V depend on the prevalence, and hence depend on the population you are focused on. This may be the UK population, a sub population with Covid-19 compatible symptoms, or any other population you may wish to target. The P P V and N P V can then be calculated using Bayes' rule:
To improve the diagnostic performance of tests they are often repeated to increase the aggregate P P V or N P V . To do this an assumption of independence between the two tests needs to be made. This assumption could be questionable in some circumstances. For instance, it would be questionable if samples are analysed at the same time in the same lab by the same technician, or if the same method for extracting the sample from the patient is employed, it may be unsuccessful at detecting virus for the same reason. A plethora of other possible errors are imaginable. Many of these errors may be truly random, and independent, but many may not be so the independence assumption may be weakly justified.
The rapid development and scaling of new diagnostic systems invites error, particularly as labs are converted from other purposes and technicians are placed under pressure, and variation in test collection quality, reagent quality, sample preservation and storage, and sample registration and provenance. Assessing the magnitude of these errors on the performance of tests is challenging in real time. Point-ofcare tests are not immune to these errors and are often seen as less accurate than laboratory based tests [18, 19] .
The prevalence of the disease matters. The P P V can vary drastically for different populations with different prevalence. The idea that prevalence depends on the population may seem counterintuitive to some audiences. For example, if we were to select 100 people from a respiratory ward this week from any hospital in the UK, and 100 people from a street outside the building, what proportion of each population have Covid-19? If one tests both populations with the same test and found positives in each population, which would have the higher P P V ? 3 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 22, 2020 To illustrate the impact of prevalence on P P V , for a test with σ = τ = 0.95 if prevalence p = 0.05, then the P P V ≈ 0.48. Figure 1 shows why, for 1000 test subjects there will be similar numbers of true and false positives even with high sensitivity and specificity of 95%. In contrast, using the same tests on a sample with a higher prevalence p = 0.5 we find the P P V = 0.8, see Figure 2 . Similarly, the N P V is lower when the prevalence is higher.
The number of active cases exceeding the test capacity may not be the only discrepancy between the true cases and reported cases. The impact of uncertainty in testing may also be contributing to the discrepancy, even in the tested population. More testing will not reduce this uncertainty. The director of the WHO suggests that testing is a crucial part of any strategy [20] , but even testing the entire country every day would not give an accurate tally of infections.
To explore the effect of imperfect testing on the disease dynamics when strategies are employed to relax the current social distancing measures the SIR model described in the supplimentary material was modified. Three new classes were added to the model, the first is a quarantined susceptible state, Q S , the second is a quarantined infected state, Q I , and the third is people who have recovered but are in quarantine, Q R . To model the current lock-down, the model evaluations begin with a majority of the population in the Q S (quarantined but susceptible) state. Whilst in this state the transmission rate of the disease is totally suppressed. The model evaluates each day's average population-level state transitions. There are two possible tests that can be performed:
An active virus infection test that is able to determine whether or not someone is currently infectious. This test is performed on some proportion of the un-quarantined population (S + I + R). It has a sensitivity of σ A and a specificity of τ A .
An antibody test that determines whether or not someone has had the infection in the past. This is used on the fraction of the population that is currently in quarantine but not infected (Q S + Q R ) to test whether they have had the disease or not. This test has a sensitivity of σ B and a specificity of τ B .
These two tests are used on some of those eligible for testing each day limited by the test capacity, ρ and φ respectively. A person (in any category) who tests positive in an active virus test transitions into the (corresponding) quarantine state, where they are unable to infect anyone else. A person, in Q S or Q R , who tests positive in an antibody test transitions to S and R respectively.
For this parameterisation the impact of being in the susceptible quarantined state, Q S , makes an individual insusceptible to being infected. Similarly, being in the infected quarantined state, Q I , individuals are unable to infect anyone else. In practicality there is always leaking, no quarantine is entirely effective, but for the sake of exploring the impact of testing uncertainty these effects are neglected from the model. The participation in infection propagation of individuals in either quarantine state are idiosyncratic, and on average are assumed to be negligibly small for the sake of this analysis.
If the tests were almost perfect, then we can imagine how the epidemic would die out very quickly by either widespread infection or antibody testing with a coherent management strategy. A positive test on the former and the person is removed from the population, and positive test on the latter and the person, unlikely to contract the disease again, can join the population .
More interesting are the effects of incorrect test results on the disease dynamics. If someone falsely tests positive in the antibody test, they enter the susceptible state. Similarly, if an infected person receives a false negative for the disease they remain active in the infected state and hence can continue the disease propagation and infect further people.
4 What part will testing play in relaxing current social distancing measures?
In order to explore the possible impact of testing strategies on the relaxation of current social distancing measures several scenarios have been analysed. These scenarios are illustrative of the type of impact, 5 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 22, 2020. . https://doi.org/10.1101/2020.04. 16.20067884 doi: medRxiv preprint and the likely efficacy of a range of different testing configurations.
Immediate end to social distancing scenario: This baseline scenario is characterised by a sudden relaxation of the current social distancing measures.
Immunity passports scenario: A policy that has been discussed in the media [21, 22, 17] . Analogous to the International Certificate of Vaccination and Prophylaxis, antibody based testing would be used to identify those who have some level of natural immunity.
Incremental relaxation scenario: A phased relaxation of the government's social distancing advice is the most likely policy that will be employed. To understand the implications of such an approach this scenario has explored the effect of testing capacity and test performance on the possible disease dynamics under this type of policy. Under the model parameterisation this analysis has applied an incremental transition rate from the Q S state to the S state, and Q R to R.
Whilst the authors are sensitive to the sociological and ethical concerns of any of these approaches [23, 24] , the analysis presented is purely on the question of efficacy.
Under the baseline scenario, characterised by the sudden and complete cessation of the current social distancing measures, we explored the impact of infection testing. Under this formulation the initial conditions of the model in this scenario is that the all of the population in Q S transition to S in the first iteration.
As would be expected the model indicates the second wave is an inevitability and as many as 20 million people could become infected within 30 days, figure 4. To illustrate the sensitivity of the model to testing scenarios an evaluation was conducted with a range of infection test sensitivities, from 50% (i.e of no diagnostic value) to 98%. The specificity of these tests has a negligible impact on the disease dynamics. A false positive test result would mean people are unnecessarily removed from the susceptible population, but the benefit of a reduction in susceptible population is negligibly small. It's also very likely the infection testing would be heavily biased toward symptomatic carriers, where the prevalence of the disease is high so fewer false positives would be expected.
Two evaluations have been conducted. The first using the stated government goal of 100,000 tests per day (left graphs in figure 4 ). It remains unclear whether this aim is feasible, or if this testing capacity would include both forms of tests (antibody and active virus). The second evaluation looks at a very optimistic case where we could conduct as many as 150,000 tests per day (right graphs in figure 4 ). The authors draw no conclusions about the feasibility of achieving these levels. However the authors do wish to encourage caution that with a capacity for testing of the order targeted by the UK government, testing in isolation is not sufficient to allow any rapid cessation of the current social distancing measures without a resurgence of the virus. This caution is irrespective of test performance, even very good tests with a sensitivity of 98%, and effective isolation of cases that have tested positive, the outcome is broadly invariant.
The immunity passport is an idiom describing an approach to the relaxation of the current social distancing measures that focuses heavily on antibody testing. Wide-scale screening for antibodies in the general population promises significant scientific value, and targeted antibody testing is likely to have value for reducing risks to NHS and care-sector staff, and other key workers who will need to have close contact with Covid-19 sufferers. The authors appreciate these other motivations for the development and roll-out of accurate antibody tests. This analysis however focuses on the appropriateness of this approach to relaxing current social distancing measures by mass testing the general population. Antibody testing has been described as a 'game-changer' [25] . Some commentators believe this could have a significant impact on the relaxation of social distancing measures [22] .
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. Much of the discussion around antibody testing in the media has focused on the performance and number of these tests. The efficacy of this strategy however is far more dependent on the prevalence of antibodies in the general population. Without wide-scale antibody screening it's impossible to know the prevalence of antibodies in the general population, so there is scientific value in such an endeavour. However, the prevalence is the dominant factor to determine how efficacious antibody screening would be for relaxing social distancing measures.
Presumably, only people who test positive for antibodies would be allowed to leave quarantine. The more people in the population with antibodies, the more people will get a true positive, so more people would be correctly allowed to leave quarantine (under the paradigms of an immunity passport).
The danger of such an approach is the false positives. We demonstrate the impact of people reentering the susceptible population who have no immunity. We assume their propensity to contract the infection is the same as those without this the false sense of security a positive test may engender. On an individual basis, and even at the population level, behavioural differences between those with false security from a positive antibody test, versus those who are uncertain about their viral history could be significant. The model parametrisation here does not include this additional confounding effect.
To simulate the prevalence of antibodies in the general population the model is preconditioned with different proportions of the population in the Q S and Q R states. This is analogous to the proportion of people that are currently in quarantine who have either had the virus and developed some immunity, and the proportion of the population who have not contracted the virus and have no immunity. Of course the individuals in these groups do not really know their viral history, and hence would not know which state 8 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 22, 2020. Each column corresponds to a different antibody test sensitivity in figure 5 as titled. The specificity for each test in these evaluations was fixed to 90%. In figure 6 each column corresponds to a different antibody test specificity as titled. The sensitivity for each test in these evaluation was fixed to 95%. For all model evaluations in figures 5 and 6 we modelled a continuing and constant ability to conduct targeted active virus testing which continued to remove individuals from the infected population. The infection testing continued throughout each model run with a fixed capacity of 10,000 tests per day, similar to the number of unique individuals that are currently being tested.
Each of the graphs in the two figures shows the effect of different prevalences of antibodies in the population. To be clear, this is the proportion of the population that has contracted the virus and recovered but are in quarantine. Sir Patrick Vallance, the UK Government Chief Scientific Advisor, in the daily press briefing on the 9 April 2020 stated his belief that this prevalence is likely to be less than 10%, possibly much less. The analysis has explored a range for prevalence from 0.1% to 50%. Figure 5 explores the impact of a variation in sensitivity, from a test with 50% sensitivity (i.e no diagnostic value) to tests with a high sensitivity of 98%. It can be seen, considering the top half of the graphs, that the sensitivity of the test has no discernible impact on the number of infections. The prevalence entirely dominates. This is possibly counter intuitive, but as was discussed in section 2.1, even a highly accurate test produces a very large number of false positives when prevalence is low. In this case that would mean a large number of people are allowed to re-enter the population, placing them at risk, with a false sense of security that they have immunity.
The bottom row of figure 5 shows the proportion of the entire population leaving quarantine over a year of employing this policy. At low prevalence there is no benefit to better performing tests. This again may seem obscure to many readers. If you consider the highest prevalence simulation, where 50% of the population have immunity, higher sensitivity tests are of course effective at identifying those who are immune, and gets them back into the community much faster. However this is not the case currently in the UK because, as Sir Patrick stated, the prevalence of antibodies is likely to be very low at least during the lock-down.
A more concerning story can be seen when considering the graphs in figure 6 . Now we consider a range of antibody test specificities. Going from 50% (no value in ruling people out) to 98%. When the prevalence is low, a lower specificity of 75% not only leads to an initial large increase in the number of infections, but also, if employed throughout the year would lead to repeated peaks. This is because the active virus testing would still be employed along side the antibody testing. Falsely-diagnosed susceptible people leaving quarantine leads to a sharp rise in the number of infections. As the prevalence of virus in the non-quarantined population increases the active virus testing becomes more effective and subdues the rise in infections because the testing is more targeted on active virus cases. This would be followed by additional waves as further false positive tests for antibodies are observed. The number of people in quarantine with antibodies declines over the length of the simulation, so naturally the prevalence of immunity in the quarantined population declines. As the prevalence declines the N P V of the test declines.
When we consider the bottom half of figure 6 and look at the impact on the proportion of the population able to leave quarantine, unlike previously, the number of false positives dominates when there is a lower specificity. So there are many more people leaving the quarantine, even when the prevalence is very low (0.1%). This may be desirable to some who favour increasing economic and social activity, but it is of course at the cost of further infections. Decision makers and the public need to be aware of the trade-off being made. The dangers of neglecting uncertainties in medical diagnostic testing are pertinent to this decision [26] , particularly if immunity passports become prominent in the strategy to end the current social distancing measures.
At this point, some form of incremental relaxation of the current government social distancing advice seems highly likely. This could take many forms, it could be an incremental restoration of certain activities such as school openings, permission for the reopening of some businesses, the relaxation of the stay-at-home messaging, etc. Under the parameterisation chosen for this analysis the model is not sensitive to any particular policy change. We consider a variety of rates of phased relaxations to the current quarantine. To model these rates we consider a weekly incremental transition rate from Q S to S, and Q R to R. In figure 7 , three weekly transition rates have been applied: 1%, 5% and 10% of the quarantined population. Whilst in practice the rate is unlikely to be uniform as decision makers would have the ability to update their timetable as the impact of relaxations becomes apparent, it is useful to illustrate the interaction of testing capacity and release rate.
The model simulates these rates of transition for a year, with a sensitivity and specificity of 90% for active virus tests. The specifics of all the runs are detailed in table 2. Figure 7 shows five analyses, with increasing capacity for the active virus tests. In each, the 3 incremental transition rates are applied with
Initial Population split σ A τ A β γ Q S S Q I Q I Q R R 0.9 0.9 0.32 0.1 0.95 0.034 0.004 0.01 0.001 0.001 Table 2 : Fixed parameters used for Figure 7 analysis. a range of disease prevalences in the population being tested. The P P V , as discussed in section 2.1, has a greater dependence on the prevalence (at lower values) in the tested population than it does on the sensitivity of the tests, the same is true of the specificity and the N P V .
It is important to notice that higher test capacities cause a higher peak of infections for the 10% quarantine release rate. This has a counterintuitive explanation. When there is the sharpest rise in the susceptible population (i.e., high rate of transition), the virus rapidly infects a large number of people. When these people recover after two weeks they become immune and thus cannot continue the spread of the virus. However, when the infection testing is conducted with a higher capacity up to 120,000 units per day, these tests transition some active viral carriers into quarantine, so the peak is slightly delayed providing more opportunity for those released from quarantine later to be infected, leading to higher peak infections. This continues until the model reaches effective herd immunity after which the number of infected in the population decays very quickly. Having higher testing capacities delays but actually worsens the peak number of infections.
At 10% release rate, up to a capacity of testing of 120,000 these outcomes are insensitive to the prevalence of the disease in the tested population . This analysis indicates that the relatively fast cessation of social distancing measures and stay-home advice would lead to a large resurgence of the virus. Testing capacity of the magnitude stated as the goal of the UK government would not be sufficient to flatten the curve in this scenario.
At the rate of 5% of the population in lock-down released incrementally each week the infection peak is suppressed compared to the 10% rate. The number of infections would remain around this level for a significantly longer period of time, up to 6 months. There is negligible impact of testing below a capacity of 50,000 tests. However if the test capacity were 80,000 tests, at a quarantine release rate of 5% the duration of the elevated levels of infections would be reduced, reducing the length of necessary wide-scale social distancing. This effect is only observed with the more targeted tests, where a prevalence of the disease in the targeted population is over 30%. Any less well targeted testing and the testing would have a negligible impact compared to the untested scenario.
The 1% release rate scenario indicates that a slow release by itself is sufficient to lower peak infections, but extends the duration of elevated infections. The first graph of the top row in figure 7 shows that the slow release rate causes a plateau at a significantly lower number of infections compared to the other release rates. Poorly targeted tested at capacities less than 100,000 show similar consistent levels of infections. However, with a targeted test having a prevalence of 30% or more, the 1% release rate indicates that even with 50,000 tests per day continuous suppression of the infection may be possible.
This analysis does support the assertion that a bad test is worse than no tests, but a good test is only effective in a carefully designed strategy. More is not necessarily better and over estimation of the test accuracy could be extremely detrimental.
This analysis is not a prediction; the numbers used in this analysis are estimates, and therefore, when such policies are devised and implemented this analysis would need to be repeated with more up-to-date numerical values. As such, the authors are not drawing firm conclusions about the absolute necessary capacity of tests. Nor do they wish to make specific statements about the necessary sensitivity or specificity of tests or the recommended rate of release from quarantine. The authors do, however, propose some conclusions that would broadly apply to the present situation, and therefore believe they should be considered by policy makers when designing strategies to tackle COVID-19.
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 22, 2020. . 12 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 22, 2020. . Diagnostic uncertainty can have a large effect on the epidemic dynamics of Covid-19 within the UK. And, sensitivity, specificity, and the capacity for testing alone are not sufficient to design effective testing procedures.
Great caution should be exercised in the use of antibody testing. Under the assumption that the proportion of people in the UK who have had the virus is still low, it's unlikely antibody testing at any scale will significantly support the end of lock-down measures. And, the negative consequences of un-targeted antibody screening at the population level could cause more harm than good.
Antibody testing, with a high specificity may be very useful on an individual basis, it certainly has scientific value, and could reduce risk for key workers. But any belief that these tests would be useful to relax lock-down measures for the majority of the population is misguided. At best it is a distraction, at worst it could be dangerous.
The incremental relaxation to lock-down measures, with all else equal, would significantly dampen the increase in peak infections, by 1 order of magnitude with a faster relaxation, and 2 orders of magnitude with a slower relaxation.
The capacity for infection screening needs to be significantly increased if it is to be used to relax quarantine measures, but only if it is well targeted, for example through effective contact tracing. Untargeted mass screening would be ineffectual and may prolong the necessary implementation of lock-down measures.
One interpretation of these results is that countries that had mass testing regimes early in the pandemic but had much lower case fatality rates may have been reporting a large number of false positives.
The results of this paper may explain what is being observed in nations such as Singapore as they continue to employ less-targeted mass testing and after a rapid cessation to their lock-down measures are now experiencing a second peak in infections [27] .
This work has been partially funded by the EPSRC IAA exploration award with grant number EP/R511729/1, EPSRC programme grant "Digital twins for improved dynamic design", EP/R006768/1, and the EPSRC and ESRC Centre for Doctoral Training in Quantification and Management of Risk and Uncertainty in Complex Systems and Environments, EP/L015927/1 .
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. 
SIR models offer one approach to explore infection dynamics, and the prevalence of a communicable disease. In the generic SIR model, there are S people susceptible to the illness, I people infected, and R people who are recovered with immunity. The infected people are able to infect susceptible people at rate β and they recover from the disease at rate γ [28] . Once infected persons have recovered from the disease they are unable to become infected again or infect others. This may be because they now have immunity to the disease or because they have unfortunately died. Figure 8 shows a schematic of the generic model formulation, and how people move between the states. Figure 9 demonstrates the typical disease dynamics, the Infected corresponding to the now well known curve that we are trying to flatten. The SIR model has two ways in which the number of new infections falls to zero. Either the number of susceptible people reduces to a point at which the disease can no longer propagate, perhaps because of a vaccine or natural immunity, or the epidemic stops if the basic reproduction rate of the disease falls below 1 due to social distancing or effective viral suppression.
.
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 22, 2020. . https://doi.org/10.1101/2020.04. 16.20067884 doi: medRxiv preprint B Binomial SIR model
The SIR model used in this paper uses discrete-time binomial sampling for calculating movements of individuals between states. For a defined testing strategy, with an active viral test having sensitivity, specificity and capacity of σ A , τ A and C A respectively, an antibody test with sensitivity, specificity and capacity σ B , τ B and C B respectively and a testing prevalence of p, these rates are defined as follows: N A = min (C A , Bin (S + I, ρ)) , (6a) N B = min (C B , Bin (Q S + Q R , φ)) , (6b) T I = min (N A p, Ip) , (6c) T S = min(S, N A − T I ), (6d) At each time step t, the model calculates the number of persons moving between each state in the order defined above. The use of a binomial model was prompted by a desire to incorporate both aleatory and epistemic uncertainty in each movement. The current approach does not make use of epistemic uncertainty, fixing the model parameters σ A , τ A , σ B , τ B , φ, ρ, C A , C B and p. A discrete time model was selected to allow for comparisons against available published data detailing recorded cases and recoveries on a day-by-day basis.
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 22, 2020. . https://doi.org/10.1101/2020.04. 16.20067884 doi: medRxiv preprint 
