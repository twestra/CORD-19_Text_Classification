clared it a pandemic [1] . As of April 8, 2020, COVID-19 has infected people in nearly every country globally and in all 50 states in the United States (US) [2] . This pandemic now poses a substantial public health threat with potentially catastrophic consequences. Reliable estimates of COVID- 19 infections, particularly at the start of the outbreak, are critical for appropriate resource allocation, effective public health responses, and improved forecasting of disease burden [3] .
A lack of widespread testing due to equipment shortages, varying levels of testing by region over time, and uncertainty around test sensitivity make estimating the point prevalence of 5] . In addition, it has been estimated that 18% [6] to 50% [7, 8] of people infected with COVID-19 do not show symptoms. Even in symptomatic infections, under-reporting can further complicate the accurate characterization of the COVID-19 burden. For example, one study estimated that in China, 86% of cases had not been captured by lab-confirmed tests [9] , and it is possible that this percentage is even higher in the US [5] . Finally, it has been suggested that the available information on confirmed COVID-19 cases across geographies may be an indicator of the local testing capacity over time (as opposed to an indicator of the epidemic trajectory). Thus, solely relying on positive test counts to infer the total number of COVID-19 infections, and the epidemic trajectory, may not be sensible [10] .
The aim of this study is to develop alternative methodologies, each with different sets of inputs and assumptions, to estimate the weekly prevalence of COVID-19 in each state in the US. One such approach is to analyze region-specific changes in the number of individuals seeking medical attention with influenza-like illness (ILI), defined as having a fever in addition to a cough or sore throat. The significant overlap in symptoms common to both ILI and COVID-19 suggests that leveraging existing disease monitoring systems, such as ILINet, a sentinel system created and maintained by the United States Centers of Disease Control and Prevention (CDC) [11, 12] , may offer a way to estimate the prevalence of COVID-19 without needing to rely on COVID-19 testing results. Importantly, recent regional increases in ILI in conjunction with stable or decreasing influenza case numbers present a discrepancy (or an increase in ILI not explained by an increase in influenza) that can be used to impute COVID-19 cases.
A second and related approach uses ILI data to deconfound COVID-19 testing results from state-level testing capabilities. These two methods show that existing ILI surveillance systems provide a useful signal for measuring COVID-19 prevalence in the US, especially during the early stages of the outbreak. A third and final approach, which uses reported COVID-19-attributed deaths to estimate COVID-19 prevalence and improves upon previously introduced methodologies [13, 14, 15, 16] is presented. COVID-19 deaths may represent a lower-noise estimate of cases than surveillance testing given that patients who have died are sicker, more likely to be hospitalized, and thus more likely to be tested than the general infected population.
While previous work has attempted to quantify COVID-19 prevalence in the United States using discrepancies in ILI trends [17, 18] , to the best of our knowledge this study is the first to offer a range of estimates at the state level, leveraging a suite of complementary methods based on different assumptions. We believe that this provides a more balanced picture of the uncertainty over COVID-19 prevalence in each state. While our results are approximations and depend on a variety of (likely time-dependent) estimated factors, we believe that our presented case counts better represent prevalence than simply relying on laboratory-confirmed COVID-19 tests. Providing such estimates for each state enables the design and implementation of more effective and efficient public health measures to mitigate the effects of the ongoing COVID-19 epidemic outbreak. While the scope of this paper is focused on the United States, the methods introduced here are general enough that they may prove useful to estimate COVID-19 burden in other locations with comparable disease (and death) monitoring systems.
We implement four methods based on three complementary approaches to estimate the prevalence of COVID-19 within the US from March 1st to April 4th, 2020. These dates correspond to the early stages of the outbreak (with fewer than 50 confirmed cases in the US), up to the date of the most recent available CDC reports as of April 16th. The first two methods, labeled div-IDEA and div-Vir, fall under the Divergence approach, which first estimates what the level of ILI activity across the US would have been if the COVID-19 outbreak had not occurred. Each method develops a control time series and uses the unexpected increase in ILI rate over the control to infer the burden of COVID-19. div-IDEA is based on an epidemiological model, the IDEA model [19] , fitted to the observed 2019-2020 ILI (prior to the introduction of COVID-19 to the US), while div-Vir is based on the time-evolution of empirical observations of positive virological influenza test statistics. The third method, based on the COVID Scaling approach, leverages healthcare ILI visits and COVID-19 test statistics to directly infer the proportion of ILI due to COVID-19 in the full population. The fourth method, based on the mortality MAP (mMAP ) approach, uses the time series of COVID-19-attributed deaths in combination with the observed epidemiological characteristics of COVID-19 in hospitalized individuals, to infer the latent disease onset time series, which is then scaled up to estimate case counts using the expected infection fatality ratio (IFR). The Methods section provides extensive details on the assumptions and data sources for each of these approaches.
Each of our methods has an adjusted version, which represents our best guess taking into account all information available to us, and an unadjusted version, which uses pre-COVID-19 baseline information. Specifically, the adjusted divergences (div-IDEA and div-Vir ) and COVID Scaling methods incorporate an increased probability that an individual with ILI symptoms will seek medical attention after the start of the COVID-19 outbreak based on recent survey data [20, 21] . The adjusted mMAP method supplements the confirmed COVID-19 deaths with unusual increases in pneumonia-related deaths across the country that may represent untested COVID-19 cases. In most states, as seen in Fig. 1 , the adjusted estimates from each method are more closely clustered than their unadjusted counterparts, increasing our confidence in the adjusted range estimates of COVID-19 prevalence.
We produced estimates for the national and state levels using these four methods for the time period between March 1, 2020 and April 4, 2020. These methods estimate that there had been 2.7 to 8.3 million COVID-19 cases in the US; in comparison, around 311,000 positive cases had been officially recorded during that time period. Fig. 1 displays the COVID-19 case count estimates from our methods at the national and state levels (and New York City) compared with the reported case numbers. The results suggest that the estimated true numbers of infected cases are uniformly much higher than those reported.
For reference, if one only adjusts the number of reported cases by the (likely) percentage of asymptomatic cases (18% [6] to 50% [7, 8] ) and symptomatic cases not seeking medical attention (up to 73% [22] ), one would conclude that the actual number of cases is higher, and about four to eight times the number of reported cases; this ratio would also be constant across states. In contrast, our methods frequently estimate 10-fold to 100-fold more cases than those reported and show significant state-level variability. The median estimate for the ratio of actual cases to reported cases for the adjusted div-IDEA method is 23 (with a 90% interval from 6 to 114), for adjusted div-Vir is 25 (5, 88), for adjusted COVID-Scaling is 14 (3, 62) , and for adjusted mMAP is 9 (4, 14) . This highlights that models using only confirmed test cases may significantly underestimate the actual COVID-19 prevalence in the United States, which is consistent with what previous studies have shown [9, 18] .
These methods also provide separate cumulative case estimates for each week within the studied period (mMAP provides daily estimates, but these are aggregated by week for comparison). Fig. 3 highlights the rapid increase in estimated COVID-19 cases over the United States as well as in New York City, Washington, and Louisiana, three locations which experienced early outbreaks. These 4 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 23, 2020. . methods suggest that states under-reported COVID-19 case counts even early in March, likely due to limited testing availability. In New York and Louisiana, the estimates were more similar across methods than in Washington. Since Washington had already experienced an outbreak by February 28 [23] , testing shortages may have been more pronounced than in the other states. Our divergence analysis approach does not rely on any COVID-19 testing data and therefore may provide more accurate estimates in Washington.
Using the adjusted versions of our methods, we estimate between 14 and 33 states (31 using the median adjusted estimate) have actual case counts above 10 times the reported counts, depending on the method (Figs. 1 and 2). Five locations have at least one adjusted estimate above 100 times the reported counts (Nebraska, Oregon, Missouri, Hawaii, and Puerto Rico). Furthermore, our methods suggest that places with low official case counts, such as Alaska, Wyoming, South Dakota, and North Dakota, are in fact experiencing significantly more COVID-19 cases than are being tested. Even places with high official case counts, such as Georgia, Pennsylvania, and Texas, appear to be significantly under-reporting. As expected, our methods produce consistent high estimates in New York and New Jersey, which have reported especially high numbers of confirmed cases; though, compared to other states, New York reports a relatively high percentage of its predicted cases across all methods, suggesting that under-reporting may be less of a problem there.
All four methods generally agree on the ordering of states by case count (Table 1) . Furthermore, they show strong rank correlations (larger than 0.65 across states and methods) with the reported case counts. mMAP has an especially high 0.96 correlation with the reported case counts, which is likely because official COVID-19 deaths and positive COVID-19 cases represent the same pool of patients and are therefore subject to the same bias. The other methods, however, rely on aggregate data from ILINet, which may cover a different set of patients. While the rank-correlation across methods is high, mMAP generally yields lower estimates than the others (Fig. 2 ). One possible explanation is that many deaths caused by COVID-19 are not being officially counted as COVID-19 deaths because of a lack of testing (and that accounting for increased pneumonia deaths does not fully capture this) [24] ; further evidence of this reasoning is that New York City started reporting plausible COVID-19 deaths (as in, not needing a test result) [25] , and mMAP 's estimates are closer (and actually higher) than the other methods' estimates there.
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04.18.20070821 doi: medRxiv preprint Figure 1 : (On previous page) COVID-19 case count estimates compared with reported case counts at the national and state levels (and New York City) from March 1, 2020 to April 4, 2020. Cases are presented on a log scale. Adjusted methods take into account increased visit propensity (div-IDEA, div-Vir, COVID Scaling) and pneumonia-recorded deaths (mMAP ). In places where the ILI-based methods show no divergence in observed and predicted ILI visits, the estimates of COVID-19 cannot be calculated and are not shown. Note that Florida does not provide ILI data, so only mMAP could be estimated there. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. 
We present four methods based on three distinct approaches to estimate the COVID-19 prevalence across the United States. The methods are complementary, in that they rely on different assumptions and use diverse datasets. Despite their clear differences, these methods estimate that the likely COVID-19 prevalence varies from 10 to 100 times higher, at the state level, than what has been reported so far in the U.S. As of April 16th, 2020, about 650,000 COVID-19 cumulative cases have been reported in the US. Assuming our (national) multiplicative factors to be good approximations for what took place from April 4th to April 16th, the current cumulative number of COVID-19 cases nationally could be anywhere from 6 to 16 million (9-fold to 25-fold higher than confirmed cases).
By design and due to the utilized data sources, our estimates using data from ILINet and confirmed cases (Divergence method and COVID-Scaling) likely better capture the number of COVID-19 cases as they would be detected at the time of hospitalization; thus, they may be inherently lagged by roughly 12 days after initial infection [26] . Considering an empirical (and likely naive) doubling time of a week, this means the prevalence of COVID-19, at any point in time (and stage of infection), could be 2-4 times higher than the estimates presented here. Taking this lag into consideration would suggest that it is plausible that up to 32 million cases individuals may be infected as of April 16th (50-fold higher than confirmed cases).
By providing ranges of estimates, both within and across models, this suite of methods offers a robust picture of the uncertainty in state-level COVID-19 case counts. When making public health decisions to respond to COVID-19, it is important to account for the uncertainty in estimates of case prevalence; the multiple estimates presented here provide a better picture of this than single point estimates.
Our approaches could be expanded to include other data sources and methods to estimate 8 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . prevalence, such as Google searches [27, 28, 29] , electronic health record data [30] , clinician's searches [31] , and/or mobile health data [32] . Accurate and appropriately-sampled serological testing would provide the most accurate estimate of prevalence and would be useful for public health measures, especially when attempting to relax current shelter-in-place recommendations. In addition, appropriately-designed studies based on serologiucal testing could be used to evaluate the reliability of the methods presented in this study. This could inform prevalence estimation methods for COVID-19 in other countries as well as for future pandemics. The ILI-based methods presented in this study demonstrate the potential of existing and well-established ILI surveillance systems to monitor future pandemics that, like COVID-19, present similar symptoms to ILI. This is especially promising given the WHO initiative launched in 2019 to expand influenza surveillance globally [33] . Incorporating estimates from influenza and COVID-19 forecasting and participatory surveillance systems may prove useful in future studies as well [34, 35, 36, 37, 38, 39] .
Limitations. The uncertainty and bias of each individual method should be considered carefully. The Divergence methods suffer from the same challenges faced when attempting to scale CDC-measured ILI activity to the entire population [40] . In particular, scaling to case counts in a population requires estimates for p(visit), the probability that a person seeks medical attention for any reason, and p(visit | ILI) which captures health care seeking behavior given that a person is experiencing ILI; these estimates are likely to change over time, especially during the course of a pandemic. Moreover, the weekly prevalence estimates from this method decrease towards the end of March, perhaps caused by a change in health care seeking behavior after the declaration of a national emergency on March 13, 2020 and the widespread implementation of shelter-in-place mitigation strategies. COVID Scaling relies on the assumption that COVID-19 positive test proportions uniformly represent the pool of all ILI patients and that shortages in testing do not bias the positive proportion upward or downward. Finally, mMAP is limited by assumptions of the Infection Fatality Rate, the distribution of time from case onset to death, and accurate reporting of COVID-19 deaths (or in the case of adjusted mMAP, that excess pneumonia deaths capture all unreported COVID-19 deaths). A high-level summary of the three methods, their estimation strategy, and their assumptions are provided in Table 2 .
We have presented three complementary approaches for estimating the true COVID-19 prevalence in the United States from March 1 to April 4, 2020 at the national, state, and city (New York City) levels. The approaches rely on different datasets and modeling assumptions in order to balance the inherent biases of each individual method. While the case count estimates from these methods vary, there is general agreement among them that the actual state-level case counts are likely 10 9 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04. 18.20070821 doi: medRxiv preprint to 100 times greater than what is currently being reported.
A more accurate picture of the burden of COVID-19 is actionable knowledge that will help guide and focus public health responses. Inevitably, as social distancing measures are relaxed, there will be a resurgence in cases. Yet, if the true case counts are near the upper bound of our estimated counts, then a substantial proportion (up to 10%) of the US population may have already been infected. In such a scenario, the US population may be closer to herd immunity than previously anticipated, and we may expect that subsequent waves of infection will eventually decrease in magnitude, until COVID-19 becomes a relatively controllable seasonal affliction like influenza [41] .
CDC ILI and Virology: The CDC US Outpatient Influenza-like Illness Surveillance Network (ILINet) monitors the level of ILI circulating in the US at any given time by gathering information from physicians' reports about patients seeking medical attention for ILI symptoms. ILI is defined as having a fever (temperature of 37.8+ Celsius) and a cough or a sore throat. ILINet provides public health officials with an estimate of ILI activity in the population but has a known availability delay of 7 to 14 days. National level ILI activity is obtained by combining state-specific data weighted by state population [12] . Additionally, the CDC reports information from the WHO and the National Respiratory and Enteric Virus Surveillance System (NREVSS) on laboratory test results for influenza types A and B. The data is available from the CDC FluView dashboard [11] . We omit Florida from our analysis as ILINet data is not available for Florida.
The US case and death counts are taken from the New York Times repository, which compiles daily reports of counts at the state and county levels across the US [42] . For the mMAP validation in the supplementary materials, the case and death counts from other countries are taken from the John's Hopkins University COVID-19 dashboard [43] . Counts are taken up until April 14, 2020.
In addition, daily time series containing positive and negative COVID-19 test results within each state were obtained from the COVID Tracking Project [44] .
The age-stratified, state-level population numbers are taken from 2018 estimates from the US census [45] .
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04.18.20070821 doi: medRxiv preprint
Viewing COVID-19 as an intervention, this approach aims to construct control time series representing the counterfactual 2019-2020 influenza season without the effect of COVID-19. While inspired by the synthetic control literature [46, 47] , we are forced to construct our own controls since COVID-19 has had an effect in every state. We formulate a control as having the following two properties:
1. The control produces a reliable estimate of ILI activity.
We construct two such controls, one model-based and one data-driven.
The Incidence Decay and Exponential Adjustment (IDEA) model [19] is a single equation epidemiological model that estimates disease prevalence over time early in an outbreak while accounting for control activities and behaviours. The model is as follows:
where I(t) is the incident case count at serial interval time step t. R 0 is the basic reproduction number, and d is a discount factor modeling reductions in the effective reproduction number with time due to public health interventions, changes in public behavior, or environmental factors. The IDEA model has been shown to be identical to Farr's law for epidemic forecasting and can be expressed in terms of a susceptible-infectious-removed (SIR) compartmental model with improving control [48] .
We fit the IDEA model to ILI case counts from the start of the 2019-2020 influenza season to the last week of February 2020. The start of the 2019-2020 influenza season is defined in a location specific manner as the first occurrence of two consecutive weeks with ILI activity above 2%. Model fitting is done using non-linear least squares with the Trust Region Reflective algorithm as the optimizer. Next, the model is used to predict what ILI would have been had the COVID-19 pandemic not occurred. In other words, we use the IDEA model ILI estimates as the counterfactual when assessing the impact of the COVID-19 intervention. When fitting the IDEA model, we use a serial interval of half a week, consistent with the serial interval estimates from [49] for influenza. We note that serial interval estimates from [50] for COVID-19 as well as from [51] for SARS-CoV-1 are longer than that of influenza, but that is not an issue as we use IDEA to model ILI.
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. .
As an alternative control to the IDEA model, we also present an estimator of ILI activity using influenza virology results. As suggested by [17] , there has been a divergence in March between CDC measured ILI activity and the fraction of ILI specimens that are influenza positive. Clinical virology time series were obtained from the CDC virologic surveillance system consisting of over 300 laboratories participating in virologic surveillance for influenza through either the US WHO Collaborating Laboratories System or NREVSS [12] . Total number of tests, total influenza positive tests, and percent positive tests are our variables of interest.
None of the three time series satisfy both properties of a valid control, as defined in 5.1. Total specimens and percent positive do not satisfy property 2 since total specimens is directly susceptible to increase when ILI caused by COVID-19 is added. Total positive flu tests satisfies property 2, but also depends on ILI through the quantity of tests administered.
We propose a modification that satisfies the properties. Let F + t , N t , I t denote positive flu tests, total specimens, and ILI visit counts respectively. In addition, let F t be the true underlying ILI counts. For any week t we assume the following relation:
There are two interpretations of this quantity: 1) It extrapolates the positive test percentage (F + t /N t ) to all ILI patients (I t ), a quantity known in the mechanistic modeling literature as ILI+ [52] . 2) Test frequency is a confounder in the relationship between the number of positive tests (F + ) and total flu (F t ). Adjusting for test frequency closes the indirect pathway between F t and F + t [53] . In the Supplementary Material, we demonstrate over a series of examples that this estimator behaves as desired. Each estimate of F t is then scaled to population ILI cases using least squares regression over pre-COVID-19 ILI counts.
In order to fit the IDEA and virology models, we estimate the ILI case count in the population from the CDC's reported percent ILI activity, which measures the fraction of medical visits that were ILI related.
In a similar fashion to the approach of [40] , we can use Bayes' rule to map percent ILI activity to an estimate of the actual population-wide ILI case count. Let p(ILI) be the probability of any person having an influenza-like illness during a given week, p(ILI | visit) be the probability that a person seeking medical attention has an influenza-like illness, p(visit) be the probability that a 12 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. person seeks medical attention for any reason, and p(visit | ILI) the probability that a person with an influenza-like illness seeks medical attention. Bayes' rule gives us
is the CDC's reported percent ILI activity, for p(visit) we use the estimate from [40] of a weekly doctor visitation rate of 7.8% of the US population, and for p(visit | ILI) we use a base estimate of 27%, consistent with the findings from [22] . Once p(ILI) is calculated, we multiply p(ILI) by the population size to get a case count estimate within the population.
We note that health care seeking behavior varies by region of the United States as shown in [22] . To better model these regional behavior differences, we adjust p(visit | ILI), the probability that a person with an influenza-like illness seeks medical attention, using regional baselines for the 2019-2020 influenza season [12] .
Additionally, because our method estimates the increase in ILI visits due to the impact of COVID-19, we must distinguish an increase due to COVID-19 cases from an underlying increase in medical visit propensity in people with ILI symptoms. Due to the widespread alarm over the spread of COVID-19, it would not be unreasonable to expect a potential increase in ILI medical visits even in the hypothetical absence of true COVID-19 cases.
For this reason, we also explore increasing p(visit | ILI) from 27% to 35% to measure the possible effect of a change in health care seeking behavior due to COVID-19 media attention and panic. The increase of p(visit | ILI) to 35% is consistent with health care seeking behavior surveys done after the start of COVID-19 [20, 21] . The Divergence and COVID Scaling methods have adjusted versions which incorporate this shift as well as unadjusted versions that keep the baseline 27% propensity.
The ultimate goal is to estimate the true burden of COVID-19. The IDEA and virology predicted ILI case counts can be used to estimate CDC ILI had COVID-19 not occurred. In other words, the IDEA and virology predicted ILI can be used as counterfactuals when measuring the impact of COVID-19 on CDC measured ILI. The difference between the observed CDC measured ILI and the counterfactual (IDEA predicted ILI or virology predicted ILI) for a given week is then the estimate of COVID-19 case counts for that week. Fig. 4 shows example observed CDC measured ILI, IDEA model predicted ILI, and virology predicted ILI. The supplementary materials contain similar plots to Fig. 4 for all locations. For this method as well as the following two, we start 13 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04.18.20070821 doi: medRxiv preprint estimating COVID-19 case counts the week starting on March 1, 2020. We note that while the IDEA and virology ILI predictions tend to track CDC ILI well earlier in the flu season, after COVID-19 started to impact the United States there is a clear divergence between predictions and observed CDC ILI, with CDC ILI increasing while the counterfactual estimates decrease. Figure 4 : COVID-19 is treated as an intervention, and we measure COVID-19 impact on observed CDC ILI, using IDEA model predicted ILI and virology predicted ILI as counterfactuals. The difference between the higher observed CDC ILI and the lower IDEA model predicted ILI and virology predicted ILI is the measured impact of COVID-19. The impact directly maps to an estimate of COVID-19 case counts. Virology predicted ILI is omitted when virology data is not available.
This approach infers the COVID-19 fraction of the total ILI by extrapolating testing results obtained from the COVID Tracking Project [44] , following the same reasoning as the Virology Di-14 .
CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04.18.20070821 doi: medRxiv preprint vergence method. That is,
where C + t , N c t , I t denote positive COVID-19 tests, total COVID-19 specimens, and ILI visit counts respectively.
State-level testing results were aggregated to the weekly level and positive test percentages were computed using the positive and negative counts, disregarding pending tests. Positive test counts were adjusted for potential false negatives. There are varying estimates for the false negative rate for the RT-PCR used in COVID-19 tests, with some reports suggesting rates as high as 25-30% [54, 55] . We apply a 15% false negative rate in our analysis; repeating our analysis using a range of values from 5% to 25% yielded little difference in our estimates. On the other hand, COVID-19 testing is highly specific, so we assume no false positives. Then, the number of false negatives (F N ) can be computed from the recorded (true) positives (T P ) and the false negative rate (f nr) as
Because COVID-19 testing is sparse in many states, there are issues with zero or low sample sizes, as well as testing backlogs. Rather than taking the empirical positive test percentage (C + t /N c t ), we first smoothed the percentages over time by taking convex combinations with the probabilities from the previous weeks, weighted by relative specimen count. This has a Bayesian posterior interpretation and is mathematically equivalent to computing probabilities using cumulative positive and total counts instead of in-week counts (for convenience, C + t and N c t henceforth refer to these respective quantities). This helped but did not address all issues with case backlog, so we further smoothed the estimates using a Bayesian spatial model:
Denote p jt as the probability that a given ILI patient in state j and week t has COVID-19. Under the condition that testing is applied uniformly, the COVID-19 status of patient i from state j in week t is X
Assuming COVID-19 status is independent in each ILI patient, the state testing results follow a Binomial distribution. We apply a spatial prior based on first-order conditional dependence:
where N j are the neighbors of state j. The strength of the prior was specified by setting N 0t to be the number of total tests at the 5th quantile among all states in each week. Finally, we compute α jt 15 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. . by replacing each p kt by their empirical estimates. Using the Beta-Binomial conjugacy we derive closed-form posterior mean estimates for p jt :
As previously explained, the weekly, state-level reported percent ILI were then multiplied bŷ p jt to get an estimate of the percent of medical visits that could be attributed to COVID-19. These values were subsequently scaled to the whole population using the same Bayes' rule method as described in ILI Case Count Estimation (4.2.3).
Other studies have introduced methods to infer COVID-19 cases from COVID-19 deaths using (semi-)mechanistic disease models [15] or statistical curve-fitting based on assumptions of epidemic progression [16] , but, to the best of our knowledge, no methods have been proposed to directly infer cases without either of these assumptions.
Mortality Map (mMAP ) uses, under a Bayesian framework, reported deaths to predict previous true case counts. mMAP accounts for right-censoring (i.e. COVID-19 cases that are not resolved yet) by adapting previously used methods [13] . A study of clinical cases in Wuhan found that the time from hospitalization to death roughly follows a log-normal distribution with mean 13 and standard deviation 12.7 [26] . Using this distribution, a time series of reported deaths, D, and the age-adjusted IFR, we estimate the distribution of cases C, defined at the usual time of hospitalization, using an iterative Bayesian approach. We use Bayes' rule to define the probability that there was a case on day t given a death on day τ p(case on t | death on τ ) = p(death on τ | case on t) · p(case on t) p(death on τ )
Let C d * denote the predicted distribution of when D are classified as cases (i.e. are hospitalized), C d denote the predicted distribution of when D and future deaths are classified as cases (so adjusted for right-censoring), and t max denote the most recent date with deaths reported. Let p(death on τ | case on t) = p(T = (τ − t)) denote the log-normal probability. mMAP performs the following steps:
1. Initialize the prior probability of a case on day t, p 0 (case on t), as uniform.
2. Repeat the following for each iteration i:
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint this version posted April 23, 2020. .
where the denominator is equivalent to p(death on τ ) in (1).
• We estimate that the proportion p(T ≤(t max − t)) of C (i) d (t) have died by t max and use this to adjust for right censoring.
• Update prior probabilities
where is a pre-specified tolerance level.
3. C d (t) represents the number of cases on day t that will lead to death. We scale this to estimate the number of all cases by divide by the IFR.
mMAP has connections to expectation-maximization, though further theoretical work is needed to establish the connection. We found that mMAP performs significantly better than using independent maximum-likelihood based estimates [i.e. solving C d * (t) = tmax τ =t+1 D(τ ) · p(T = (τ − t))].
Supplementary section 4.2 demonstrates that mMAP successfully predicts cases in simulated and true scenarios using data from six countries. As well, supplementary section 4.1 demonstrates that if mMAP converges, which it does for every US state, C d fully explains deaths under the assumed probability distribution (6) , and that this satisfies the calculation of the fatality rate as presented in [13] .
The IFR for each state is calculated using the age-stratified fatality rate [56] , which estimates IFR of all cases -symptomatic and asymptomatic, and the population age structure provided by the US census [45] .
While mMAP assumes all COVID-19 deaths are reported, some deaths will be unreported because of a limited testing and false negative results [57] . Previous research on the H1N1 epidemic estimated that the ratio of lab-confirmed deaths to actual deaths caused by the disease was 1:7 nationally [58] and 1:15 globally [59]. While the actual rate of under-reporting is unknown, we include an adjustment, mMAP adj , that uses an estimate of unreported COVID-19 deaths based on reports of excess pneumonia deaths (note that this is similar to the divergence methods, except that those measure excess ILI visits). mMAP adj assumes that excess pneumonia deaths in March 2020 were due to COVID-19.
The CDC reports weekly pneumonia deaths, D P (w), expected weekly pneumonia deaths based on a model of historical trends, E[D P (w)], and deaths that are classified as pneumonia and COVID-19, D P ∩COV (w) [60, 61] . We estimate that the number of un-classified COVID-19 deaths each week, D U (w), is the following:
This results in 355, 438, 605, and 540 nationwide excess deaths for the four weeks from March 1 to March 28, which is the most recent data at the time of writing this paper. To account for missing data in recent weeks, We assume that the weekly number of excess deaths remains constant after March 21, i.e. that there were 540 excess deaths the weeks of March 29 -April 4 and April 5 -April 11. Since the expected pneumonia deaths are not available at the state level, excess deaths are calculated nationally and then attributed to each state s in proportion to the number of pneumonia deaths in that state. Then, the weekly excess deaths are evenly distributed across each day of the week.
The divergence-based methods predict national COVID-19 prevalence directly using national ILI data. mMAP predicts national prevalence using national death data, while COVID Scaling estimates national prevalence by aggregating the case estimates from each state.
The Divergence and COVID Scaling methods provide separate case estimates for each week within the studied period, which are summed to the total cumulative case estimates. mMAP provides daily estimates which are further aggregated by week.
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 23, 2020. 2. The distribution of time from cases to death is log-normal.
3. The age-stratified IFR is the same as reported in [56] .
This method can be sensitive to model fit and changes in healthcare seeking behavior among symptomatic individuals.
ILI visits and COVID-19 tests may capture different segments of the sick population.
May underestimate cases as many COVID-19 related deaths may go unreported or untested. 
. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04.18.20070821 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04.18.20070821 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)
The copyright holder for this preprint this version posted April 23, 2020. . https://doi.org/10.1101/2020.04. 18.20070821 doi: medRxiv preprint 
