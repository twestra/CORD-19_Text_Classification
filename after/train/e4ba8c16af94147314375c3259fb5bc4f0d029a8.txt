Testing strategies for to maximize number of people tested are urgently needed. Recently, it has been demonstrated that RT-PCR has the sensitivity to detect one positive case in a mixed sample of 32 cases [12] , In this paper we propose adaptive group testing strategies based on generalized binary splitting (GBS) [5], where we restrict the group test to the largest group that can be used. The method starts by choosing a group from the population to be tested, performing a test on the combined sample from the entire group, and progressively splitting the group further into subgroups. Compared to individual testing at 4% prevalence, we save 74%; at 1% we save 91%; and at .1% we save 98% of tests. We analyze the number of times each sample is used and show that the method is still ecient if we resort to testing a case individually if the sample is running low.
In addition we recommend clinical screening to lter out individuals with symptoms and show this leaves us with a population with lower prevalence. Our approach is particularly applicable to vulnerable conned populations such as nursing homes, prisons, military ships and cruise ships.
Testing capacity for COVID-19 is still too scarce to meet the needs to meet global health needs. Conned populations are at particular risk for rapid contagion. They may include those who reside in facilities such as prisons, ships, military units and nursing homes. The goal of this paper is to increase the capacity to identify asymptomatic carriers of COVID-19 by applying group testing methods. Current practice typically involves a one-patient-one-test strategy. Recently the potential to detect COVID-19 RNA in a mixture of samples from individuals has been validated [12] using RT-PCR. Group testing was rst studied mathematically in 1943 during World War II to test large groups of US servicemen for syphillis prior to deployment [3] . Now, just as in the WWII era, large scale testing is necessary.
COVID-19 is a highly contagious disease that can lead to pneumonia, acute respiratory distress syndrome (ARDS) and death. Clinical symptoms and phyiscal exam features may include fever, cough, shortness of breath, malaise, lethargy, ageusia, anosmia and gastrointestinal (GI) symptoms. Besides this disease's potential lethality, it is highly contagious.
Recently the potential of group testing using RT-PCR for nding SARS-CoV-2 RNA has been demonstrated [12] . In Europe, group-testing is currently being considered as a possible important step to totally cut-o the possibility of a resurgence as our other methods succeed in driving the rate of infection down [4] .
In Luxembourg, massive testing to nd asymptomatic carriers is underway and group testing can ll in the gaps in testing asymptomatic positive cases. In Hungary, there are plans to potentially test every person in the entire country using group-tests [6] .
There is renewed interest in the practical applications of group testing algorithms. In [8] a non-adaptive group testing method and practical applications are explored. We describe adaptive group testing methods based on generalized binary splitting (GBS) [5] . We provide an algorithmic specication for subdividing groups and account for the limited test accuracy and the possibility that the an individual's sample size constrains the number of tests. We explain how prescreening symptomatic cases and separately testing them can dramatically improve performance. Pre-screening reduces the prevalence in the test groups. This approach is relevant for large scale populations and particularly for conned groups.
1 Figure 1 .1: (Image credit: Matthew Heidemann) Our group testing method consists of rst clinically screening out symptomatic individuals. This will lower the prevalence in the test population. Our group testing is especially eective when we can assume the prevalence is uniform over the whole population. Therefore, it is especially applicable to conned or cohesive populations. We split the asymptomatic individuals up into groups for which we mix the samples from each individual and test them. A negative result will conrm many negative cases. We subsequently divide groups and test the mixtures of samples for positive results.
This, we show, conserves the number of tests and, as a result, the time spent testing. Using numerical experiments, we also show that our methods can be performed without running out of samples from passing through too many rounds.
This application utilizes a primary clinical screening step to ensure that the tested population is composed of asymptomatic COVID-19 (-) and (+) patients. This ensures the lowest prevalence of disease in the population and enhances the ecacy of the method.
Clinical screening should rst take place in the selected population to screen out as many potential positive patients as possible before administering the test. All patients with a history of cough, shortness of breath, nausea, gastrointestinal symptoms, fever, malaise, lethargy, recent contact with positive COVID-19 patients, or having a physical exam consistent with those ndings should be segregated out of the population.
. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint Clinical screening will decrease the prevalence of COVID-19 carriers in the test population if the probability of being asymptomatic given COVID-19 (+) is less than the proportion of the population that is asymptomatic (regardless of COVID-19 (+) or (-)). We demonstrate this by proving the following claim.
Claim. The sub-population not showing any symptoms will have a lower proportion of asymptomatic carriers when the proportion of people not showing any symptoms in our group is less than the estimated proportion of COVID-19 carriers who are asymptomatic.
We can prove this through a couple of applications of Bayes' theorem. We refer to the event that an individual does not show symptoms as no symptoms. The event that an individual has symptoms that are signs of COVID-19 is referred to as symptoms regardless of whether they carry the disease. We denote the event of carrying the COVID-19 virus as COVID-19. Then an asymptomatic carrier is referred to as no symptoms and COVID-19. Let P (A) denote the probability of an event A occuring. Written in terms of probabilities, screening will help when P (COVID-19|no symptoms) < P (COVID-19).
Re-writing the left side of the inequality, we get P (COVID-19|no symptoms) = P (COVID-19 and no symptoms) P (no symptoms) = P (no symptoms|COVID-19) P (no symptoms) P (COVID-19).
3 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint Therefore it is necessary and sucient for P (no P (no symptoms) < 1, which is the same as P (no symptoms|COVID-19) < P (no symptoms). This is the probability of being asymptomatic given that they have COVID-19 for the population we are testing.
If a population has a low prevalence of COVID-19 then it is likely for groups of individuals to not have any positive cases. Therefore it is often the case that one test of the mixture of their samples is all that is needed to determine that they are all negative. testing a mixture of samples from the individuals in the group. The maximum group size in this example is 8. A blue frame represents testing (-) for COVID-19 and a red frame represents testing (+). Two of the group tests of 8 are positive. When this happens, a type of binary search is used to nd one positive case.
In this example 32 cases are conrmed either (+) or (-) using 11 tests. Some cases are left un-determined for future rounds of testing.
Otherwise, a positive result on the combined samples indicates that there are some positive cases. We are therefore able to design a strategy to use less tests to determine whether each individual is positive or negative for the disease by testing mixtures of samples from groups.
To suciently identify negative cases and positve cases the groups must be large enough to balance nding many negative cases with one test, and locating some positive cases.
Step one of the group test method is: 1. A group size is chosen so that the frequency that a group has only (-) cases (gure 3.1)
is roughly equal to the probability we nd at least one (+) case in the group. 4 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint Table 3 .1: Group size specied for the divide and test method. By DTg we mean to apply divide and test, using the minimum of g and the group size for divide and test (e.g. DT32 will use a group of size 32 if DT uses a group of size 64). We study limited group sizes to explore how many tests can be saved depending on the limitations of the instruments.
If the test of the group's combined samples is positive, indicating that one of the individuals in the group is positive, apply a routine of repeatedly dividing the group into subgroups applying tests to the subgroups until a positive individual is identied. This is step two of the group test method.
2. If the rst test is (+), divide the group into two subgroups of equal size. Test the combined sample from individuals in one subgroup to determine which halve contains some positive individuals. Repeat this step on the subgroup that contains the positive cases.
This routine is referred to as binary search.
3.1 Binary search details 5 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint not be tested in this round of binary search, so we return the cases to the test population. Finally split the remaining subgroup into two individual cases. Testing the rst case reveals that they are (-). The second case is then (+). In total: 5 (-) cases and 1 (+) case are revealed using 4 tests.
When the test result of the group's samples is (+) we split the group into two equally sized subgroups testing one of them to decide if it contains some positive cases or if it consists entirely of negative cases. In the second situation, the second half must contain positive cases.
Continue the search on the subgroup with positive cases in the same way dividing it into two halves testing the mixed samples from one of the half-subgroups. Repeating this step we are able to nd one positive case. Along the way many groups of several individual are likely to be conrmed negative with a relatively 6 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint small number of tests. Any subgroup that was not tested retains its undetermined status and is returned to the general set of samples to be conrmed positive or negative.
3. Repeat the procedure starting with 1. on the individuals in the population for which whether they carry the disease has yet to be determined.
In this paper we consider group testing methods that follow two dierent interpretations of step 1 in the procedure above: methods with a xed group size and methods where the group size changes based on the results of previous tests. Each type of method uses a slightly dierent denition of prevalence.
Prevalence is dened as the probability p an individual in the population has COVID-19. For each level of prevalence we specify a xed number of individuals to test their combined samples, performing binary search if it is positive. The xed group size method we analyze in this paper is divide and test (DT). We also consider Dorfman's method as a method to compare the methods against, as well as a simpler alternative that only ever uses an individual's samples for a maximum of two tets.
Prevalence is dened as the absolute number of positive cases in the test population. As testing is carried out, the conrmed positive and negative cases are set aside are both removed from the undetermined test population. Therefore, the population and the prevalence changes during the testing process. The group size depends on both the population and the prevalence. The adaptive group testing method presented in this paper is generalized binary splitting (GBS).
In addition to studying these two classes of methods, we make modications to the methods to take into account limitations of the devices and techniques used to test samples for COVID-19 RNA. Specically, we study methods with limited group sizes. These are DT and GBS with maximum group g (DTg and GBSg). They are dened so that any time either DT or GBS species a group size over the capped limit g we take the group size to be g. To cover a wide range of limits of detection we consider groups of sizes 4,8,16,32 and 64.
This method is can be thought of as a xed group size version of the generalized binary splitting method [5].
1. If p > .5 then test each member of the population individually. Otherwise, let α = log 2 1 p − 1 . Select a group of individuals G with |G| = 2 α and apply one test to G. If it is negative, then we conclude that the result of each case in G is negative.
2. If G is positive we use binary search to nd exactly one case that we can deduce is positive.
3. Repeat the method starting with step 1. on the yet to be conrmed portion of the population. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint .
5 Dynamic group-size method: Hwang's generalized binary splitting (GBS)
The group testing methods suggested in this paper are based on Hwang's generalized binary splitting method.
In [5] GBS is designed to nd up to D (+) cases in a population containing N individuals. It is described as follows:
Take G a group of cases such that |G| = 2 α and apply one test to G. If it is negative, then we conclude that the result of each case in G is negative.
2. If G is positive we use binary search to nd exactly one case that we can deduce is positive.
3. Set the population to the set of individuals not determined (+) or (-). We set N to be the new population size. If we have found a positive case in the last two steps, we take D − 1 to be the new number of positives in the un-tested population.
This method is extended to populations with a random number of (+) cases by setting the upper limit on positive cases according a chosen condence level (i.e. the probability that the number of (+) exceeds this is very small). In probability terms, if the number of positive cases D is generated acccording to a probability distribution, and we assume probability c that will identify every positive case, then let D c be such that P (D ≤ D c ) < c. Generalized binary splitting is then applied to nd at most D c positive cases in the population.
The setting of Hwang's paper is group testing for general purposes, including identifying defective parts or products in addition to determining individuals with a disease.
It is an ethical requirement to determine if each person is (+) or (-) if they are tested for COVID-19.
Therefore GBS is appplied for an upper bound D c of positive cases at a xed level of condence c. If exactly D c positive cases are found, then there with non-zero probability there are some cases that have not been determined. Otherwise if < D c positives are identied, then we are certain we have found them all and it will also happen that a positive or negative conrmation was given to each individual by the end of the testing process.
In the case where there could be more positive cases, we repeat GBS with the same level of condence c on the remaining population.
Rather than considering the application of a level of condence as an idiosyncracy of the method, it is actually a fundamental property of identifying asymptomatic COVID-19 carriers. Asymptomatic positives cannot be identied without testing them, we can only pick an upper bound on the cases with a high level of certainty. It might seem preferable to then choose a method that instead prescribes a group-size for each level of prevalence, such as Dorfman's method or divide and test, but for those methods the possibility that we have misjudged the prevalence still needs to be factored in! 6 Condence bounds on group testing methods We will apply DT and GBS with groups capped at 4, 8, 16, 32 and 64 samples using two dierent levels of condence.
• GBSg with D .5 (i.e. P (D ≤ D .5 ) = .5). We repeat GBSg at this level of condence if there are undetermined cases remaining.
• We apply DTg with the group size 2 log( 1 p −1) .
• GBSg with D .99 . For a population generated by a prevalence level p, this will perform worse on average than the application with D .5 , but level of eciency theoretically guarenteed for GBS [5] will hold with 99% condence. Therefore, we can be more condent of the algorithm;s performance.
• For populations of size N generated with prevalence p, we apply DTg at the actual prevalence level of the population with 99% condence. That is, we apply DTg with the group size (with ceiling g) corresponding to p .99 = D.99 N .
8 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint For small to medium sized populations, the 99% condence upper bound is very dierent from the mean.
The dierent condence levels are very close for large N for a constant probability of having COVID-19.
How condent we are needs to be taken into account in this scenario as well because assuming a uniform probability of having the disease is likely to be too broad of an assumption. There are many dierent factors that lead to sub-populations having distinct frequencies of carrying COVID-19 and the certainty about the prevalence varies as well. 7 Dorfman's method [3] We compare the results from the DT and GBS methods to Dorfman's method. Dorfman's method is as follows:
1. For a the optimal group size b (dened below), apply one test to a group of b cases. If the result is negative, then conclude that every case in the group is negative.
2. If the result is positive, test each case individually.
If the test result is negative then one test was used for b cases. If it is positive, then b+1 tests were used. The quantity b is chosen to minimize the expected number of tests used to determine the result of one individual case,
We will use this formula to compute the expected proportion of tests saved for several dierent levels of prevalence to compare to the successor binary search based methods we choose study.
8 Analysis of group testing methods methods 1
To evaluate and analyze the performance we assume that the populations are sequences of randomly generated i.i.d. variables representing cases with the probability of having the disease p. The population is then modeled by a probability distribution with the following parameters.
• N -the size of the population/number of cases • pthe probability that a case is positive. We refer to this as the prevalence.
• A case is then a Bernoulli random variable that is positive with probability p and negative with probability 1 − p.
• The number of positive cases is then a binomial random variable with N samples and probability p of a success, we write this as binomial(N, p).
• T −the number of tests needed to determine the status of every case for a population of size N . . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint
We compute the average number of bits per test by sampling populations many times and taking the mean of this quantity computed for each sample.
In section 9 we analyze the performance of the group testing methods at a selection of prevalences for populations of size 100 and 1000. In section 10 we analyze the performance at the .99 condence upper bound. This can be thought of as overestimating the prevalence by a large enough amount so that we are 99% sure that the actual number of positive cases falls at or below this level.
In section 11 we analyze the number of rounds of testing each sample goes through. Our results suggest that not only do group testing methods save tests and time, but they can be done within the realistically expected amount of usage for each test.
An analysis of the histograms of the number of tests per case from which we compute the average performances is in the numerical results section after the bibliography (section 14). 9 Performance of group testing methods at dierent prevalences Interestingly, although GBS has theoretical guarentees on the number of tests, DT has better performance on average.
. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint 
We analyze the eect of picking the prescribed method for a conservatively large estimate on the prevalence.
A larger estimate on the prevalence will still take advantage of the frequent occurence of many consecutive negative cases. The overestimate we use corresponds to a probability of having less positive cases of .99. We sample the populations at least 100 times and take the mean of the proportion of tests saved over all samples.
Specically for DTg applied to populations of 100 and 1000 we generated 100 samples. For GBSg applied to populations of size 100 we sampled 1000 times except for GBS16. For GBSg applied to populations of size 12 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint 1000 we sampled 100 times except for GBS64 we sampled 1000 times. The dierences in number of samples are due to the overall computational expense of simulating GBS and DT.
The mean savings of each numerical experiment are presented in the following 
Although demonstrated to be more ecient in test usage, generalized binary splitting requires some samples to be used at least as many times as the logarithm of initial group size. For maximum group sizes of 32 and 64 this implies that positive cases will be tested at least 6 or 7 times. As is demonstrated by gures 11.1 and 11.2 it is possible for tests to be used more than twice as many times.
. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint Figure 11 .1: For GBS32 we sample a population of size 10,000 and record the number of times each case is tested. Note that for prevalence of p = .1% a sample is used at most 5 times in the population. In gure 11.2 where we perform the same experiment we nd cases that are tested up to 9 times. We apply GBS32 to nd at most D .99 . We see in gure 11.3 that the proportion of cases that are tested many times (more than 6) is very low. This is evidence that testing the cases indivually when we are running low (if we are limited to 6 uses) adds up to less than 1% extra tests. If we are able to test a sample more than this many times, individually testing when we are about to run out eects the eciency negligibly.
14 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint Figure 11 .3: We sample a population of size 10000 at various prevalence levels and use GBS32 at the 99% condence upper bound. We plot the histograms of the number of times postive results and negative results are tested given that they are tested more than once. Interestingly, sometimes the number of times negative cases are tested seems to have a larger maximum.
Gaining knowledge of COVID positive status in asymptomatic carriers is of prime importance in the ght to contain and eliminate the disease. The group testing strategy will generate certainty and a margin of safety in conned populations and may be useful in detection of disease burden in geographically dispersed 15 . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint populations as a mode of surveillance. A key factor in our strategy is the two phase approach that we propose. Clinical screening of symptomatic patients cuts down the prevalence of Covid-19 in the chosen asymptomatic test populations.
Rapid, large scale testing is urgently needed for naval ships and military bases. A recent outbreak upon the USS Roosevelt has brought this concern to the forefront of military proporities [7] . Recently Italian prisoners have rioted rioting due to lack of testing [9] . 300 prisoners have been released from NYC prisons due to concern for spread of coronavirus [10] . Nursing homes have been sites of extensive outbreaks [11] .
In the current phase of the pandemic, testing for the presence of COVID-19 targeted antibodies using viral antigens such as the ELISA assay are being used to test for both exposure and immunity. It is an important topic to explore how antibody tests can be most eectively used in tandem with PCR tests leading to the largest possible testing capacity. Antibody tests are important especially to discover whether rst responders are potentially exposed and immune to the disease. As antibody tests are not yet produced enabling point of care usage, there is a scarcity of antibody testing capacity just as there is PCR testing capacity. Is it feasible to apply group testing methods to antibody assays?
Screening an asymptomatic population is challenging but important. Sensitivity of tests is paramount but also utilization of resources must be ecient. This study proposes a statistically valid mathematical model to optimize number of tests performed On chosen populations. The future direction of our work will require clinical validation with real world application of this group testing strategy.
The clinical screening of symptomatic patients out of our population is helpful but it will also make detecting virus in asymptomatic people potentially tougher because of the chosen viral load. Current RT-PCR methods are standard but have a concerning false negative rate in symptomatic patients [1] . This may be further exacerbated in asymptomatic patients. Future studies may explore or consider the use of more sensitive techniques including DDPCR and addition of other sampling techniques such as fecal specimens and perhaps advanced imaging such as chest CT scan.
Based on the above evidence it is clear that a comprehensive strategy is necessary to test all asymptomatic people. This strategy will uncover the hidden silent carriers of disease.
Group testing has the chance for saving tests, while giving an exit to revert to individual testing if there are more cases than estimated. These strategies are not necessarily the theoretical optimums. Nevertheless, by our calculation and numerical simulations they have the power to cut down the number of tests used.
The group testing method is applicable to conned populations from both a clinical and mathematical stand point. We can clinically screen conned groups to decrease the prevalence in a predictable way. This method allows each patient in the population to get a test result. We explore adaptive and non-adaptive strategies for group testing for COVID-19, therefore we add adaptive and binary search based non-adaptive strategies.
Both perform well even when we restrict the size of the group based on the sensitivity of RT-PCR.
We test the performance of two algorithms: divide and test and generalized binary splitting. For populations of size 100 and 1000 with each case being positive independent of one another with probability p, we nd that both methods save many tests. In fact, even when we restrict the size of the groups they make substantial savings. For example at prevalence .001 and group sizes capped at 16, both DT16 and GBS16 are capable of outperforming Dorfman's method, that requires a group size of 33 for optimal performance. For a population of 1000 and condence level .99, the DT16 and GBS16 also have a similar performance to Dorfman's method at .001 where Dorfman's method is chosen as if we knew the exact prevalence.
We nd that DT outperforms GBS on average even though GBS in theory uses close to optimal number of tests for a known xed number of (+) cases (bounded above by #tests − 1 + information lower bound). This indicates that methods based on DT have the potential to save many tests. We found that DT when applied without a capped recovers close to the optimal 1 bit of information with each group-test. If the measurement is sensitive to detect one positive in groups of size twice up to 16 as large as the current maximum, then optimally ecient testing can be carried out. It might be the case that a full binary search of the group puts too much strain on the laboratory work ow. The bit of information that gained from negative test results on large pools can be leveraged while choosing smaller sample sub-groups to carry out the process of nding positive cases.
. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint Since samples can be divided, frozen and stored for continuous use we mathematically analyze how many divisions we have to use for each sample. We nd that testing individually when the sample is about to run out does not subtract substantially from the savings. We demonstrate that for a group size of 32 the generalized binary search on 10000 cases uses the same sample more than 6 times for < 1% of all cases.
Therefore, applying a test individually to samples when they are running low is a viable way to save many tests while not depleting material from one person's sample.
[4] John Follain. Spain, italy to extend lockdowns amid renewed rise in cases.
https://www.bloombergquint.com/politics/spain-italy-to-extend-lockdowns-amid-persistent-rise-incases. Accessed: 2020-04-10.
[5] FK Hwang. A method for detecting all defective members in a population by group testing. Journal of the American Statistical Association, 67(339):605608, 1972.
[6] Fanni KaszÃ½s. Coronavirus: Whole country could be tested in a matter of days with new process? https://hungarytoday.hu/coronavirus-whole-country-could-be-tested-in-a-matter-of-days-withnew-process/. Accessed: 2020-04-02.
[ . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint .05. Again, the performance of GBS is tightly concentrated at its mean.
. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint for both GBS and DT. The maximum group size is 64. For GBS we sampled 1000 populations, for DT we sampled 100 populations. Note that the spread of the DT algorithm is much wider and has many cases that need a much lower number of tests than GBS. The small bars in GBS are caused by the 1% chance of not identifying all of the cases in one run and so repeating the process on the rest of the population.
. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20050245 doi: medRxiv preprint
