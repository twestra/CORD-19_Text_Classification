Chest X-ray is the first imaging technique that plays an important role in the diagnosis of COVID-19 disease. Due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks (CNN s) for image recognition and classification. However, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. Thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. In this paper, we validate and adapt our previously developed CNN, called Decompose, Transfer, and Compose (DeTraC ), for the classification of COVID-19 chest X-ray images. DeTraC can deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. The experimental results showed the capability of DeTraC in the detection of COVID-19 cases from a comprehensive image dataset collected from several hospitals around the world. High accuracy of 95.12% (with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of 93.36%) was achieved by DeTraC in the detection of COVID-19 X-ray images from normal, and severe acute respiratory syndrome cases. 12 disease within computed tomography (CT ). In [3], a modified version of ResNet-50 13 pre-trained network has been provided to classify CT images into three classes: healthy, 14 COVID-19 and bacterial pneumonia. Chest x-ray images (CXR) were used in [4] by a 15 CNN constructed based on various ImageNet pre-trained models to extract the high 16 : medRxiv preprint 150 COVID-19 images, we compare it with ResNet18 using the same settings. ResNet18 151 achieved accuracy of 92.5%, sensitivity of 65.01%, specificity of 94.3%, and precision of 152 94.5%. 153 Fig 3. The learning curve accuracy and error obtained by DeTraC-ResNet18 model.
Diagnosis of COVID-19 is typically associated with both the symptoms of pneumonia 2 and Chest X-ray tests. Chest X-ray is the first imaging technique that plays an 3 important role in the diagnosis of COVID-19 disease. Fig. 1 shows a negative example 4 of a normal chest x-ray, a positive one with COVID-19, and a positive one with the 5 severe acute respiratory syndrome (SARS). 6 In the last few months, World Health Organization (WHO) has declared that a new 7 virus called COVID-19 has been spread aggressively in several countries around the 8 world [1] . Fast detection of the COVID-19 can be contributed to control the spread of 9 the disease. One of the most successful algorithms that have been proved its ability to 10 diagnosis medical images with high accuracy is convolution neural network (CNN ). For 11 example, in [2] , a CNN was applied based on Inception network to detect COVID-19 level features. Those features were fed into a Support Vector Machine SVM as a 17 machine learning classifier in order to detect the COVID-19 cases. Moreover, in [5] , a 18 CNN architecture called COVID-Net based on transfer learning was applied to classify 19 the CXR images into four classes: normal, bacterial infection, non-COVID and 20 COVID-19 viral infection. 21 Several classical machine learning approaches have been previously used for 22 automatic classification of digitised chest images [6, 7] . For instance, in [8] , three 23 statistical features were calculated from lung texture to discriminate between malignant 24 and benign lung nodules using a support vector machine classifier. A grey-level 25 co-occurrence matrix method was used with Backpropagation Network [9] to classify 26 images from being normal or cancerous. With the availability of enough annotated 27 images, deep learning approaches [10, 11] have demonstrated their superiority over the 28 classical machine learning approaches. CNN architecture is one of the most popular 29 deep learning approaches with superior achievements in the medical imaging domain [12] . 30 The primary success of CNN is due to its ability to learn features automatically from 31 domain-specific images, unlike the classical machine learning methods. The popular 32 strategy for training CNN architecture is to transfer learned knowledge from a 33 pre-trained network that fulfilled one task into a new task [13] . This method is faster 34 and easy to apply without the need for a huge annotated dataset for training; therefore 35 many researchers tend to apply this strategy especially with medical imaging.
Class decomposition [14] has been proposed with the aim of enhancing low variance 37 classifiers facilitating more flexibility to their decision boundaries. In this paper, we 38 adapt and validate DeTraC [15] for the classification of COVID-19 in chest x-ray images 39 1 . This is by adding a class decomposition layer to the pre-trained models. The class 40 decomposition layer aims to partition each class within the image dataset into several 41 sub-classes and then assign new labels to the new set, where each subset is treated as an 42 independent class, then those subsets are assembled back to produce the final 43 predictions. For the classification performance evaluation, we used images of chest x-ray 44 collected from several hospitals and institutions. The dataset provides complicated 45 computer vision challenging problems due to the intensity inhomogeneity in the images 46 and irregularities in the data distribution. Then we apply the class-decomposition layer of DeTraC to simplify the local structure 52 of the data distribution. In the second phase, the training is accomplished using a 53 sophisticated gradient descent optimisation method. Finally, we use the 54 class-composition layer of DeTraC to refine the final classification of the images. As pre-trained CNN model using the collected chest X-ray image dataset. We used the 64 off-the-shelf CNN features of pre-trained models on ImageNet (where the training is 65 accomplished only on the final classification layer) to construct the image feature space. 66 However, due to the high dimensionality associated with the images, we applied PCA to 67 project the high-dimension feature space into a lower-dimension, where highly 68 correlated features were ignored. This step is important for the class decomposition to 69 produce more homogeneous classes, reduce the memory requirements, and improve the 70 efficiency of the framework. . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint 
where n is the number of images, m is the number of features, and k is the number 75 of classes. For class decomposition, we used k-means clustering [16] to further divide 76 each class into homogeneous sub-classes (or clusters), where each pattern in the original 77 class L is assigned to a class label associated with the nearest centroid based on the 78 squared euclidean distance (SED):
where centroids are denoted as c j .
Once the clustering is accomplished, each class in L will further divided into k 81 subclasses, resulting in a new dataset (denoted as dataset B).
Accordingly, the relationship between dataset A and B can be mathematically 83 described as:
where the number of instances in A is equal to B while C encodes the new labels of 85 the subclasses (e.g. C = {l 11 , l 12 , . . . , l 1k , l 21 , l 22 , . . . , l 2k , . . . l ck }). Consequently A and 86 B can be rewritten as: For fine-tuning the parameters, the learning rate for all the CNN layers was fixed to 92 0.0001 except for the last fully connected layer (was 0.01), the min batch size was 64 93 with minimum 256 epochs, 0.001 was set for the weight decay to prevent the overfitting 94 through training the model, and the momentum value was 0.9. With the limited [y j ln z x j
where x j is the set of input images in the training, y j is the ground truth labels 100 while z(·) is the predicted output from a softmax function. In this work we used a combination of two datasets:
• 80 samples of normal CXRs (with 4020 × 4892 pixels) from the Japanese Society 112 of Radiological Technology (JSRT ) [19, 20] .
• Chest X-ray images of [21] , which contains 105 and 11 samples of COVID-19 and 114 SARS (with 4248 × 3480 pixels). 115 We applied different data augmentation techniques to generate more samples such functions and three different kernel filters. We adopted the last fully connected layer 125 into three classes and initialised the weight parameters for our specific classification 126 task. For class decomposition process, we used k-means clustering [16] . In this step, as 127 pointed out in [15] , we selected k = 2 and hence each class in L is further divided into 128 two clusters (or subclasses), resulting in a new dataset (denoted as dataset B) with six 129 classes (norm 1, norm 2, COVID19 1,COVID19 2, SARS 1, and SARS 2), see Table 1 . . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . was trained based on deep learning mode. For performance evaluation, we adopted some 145 metrics from the confusion matrix such as accuracy, sensitivity, specificity, and precision. 146 The results were reported and summarised in table 2.
We plot the learning curve accuracy and loss between training and test as shown in 148 Fig 3. Also, the Area Under the receiver curve (AUC) was computed as shown in Fig 4. 149 To demonstrate the robustness of DeTraC-ResNet18 in the classification of . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20047456 doi: medRxiv preprint
